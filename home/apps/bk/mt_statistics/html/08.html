<!doctype html>
<html>
<head>
  <meta http-equiv='Content-Type' content='text/html; charset=UTF-8'>
  <meta name='viewport' content='width=device-width, initial-scale=1.0, user-scalable=1.0'>
  <title>Statistics</title>
  <link rel='stylesheet' type='text/css' media='screen' href='../../../../styles/global.css'>
  <script type='text/javascript' src='../../../../scripts/global.js'></script>
  <script>MathJax={tex: {inlineMath: [['$', '$'], ['\\(', '\\)']], processEscapes: true}};</script>
  <script id='MathJax-script' async src='../../../../scripts/MathJax/tex-chtml.js'></script>
</head>
<body>
<div id='idPanel'>
<div id='idTopbar'>
  <div id='idTopbarNavigation'>
    <a href='../../../../index.html'><span class='clNavHome'><span></a>
    <a href='../../index.html'><span class='clNavIndex'><span></a>
    <a href='../index.html'><span class='clNavUp'><span></a>
    <a href='#top'><span class='clNavContent'><span></a>
  </div>
</div>
<div id='idContent'>

<a name='top'></a><br>

<a href='javascript:fncShowHide("idDiv00")'>Table of Contents</a>
<div id='idDiv00'>
<br>
<a href='#chapter_8'>        8. Probability</a><br>
<br>
<a href='#section_33'>       8.1. What Are the Chances?</a><br>
<a href='#concept_166'>      8.1.1. Fundamentals of Probability</a><br>
<a href='#concept_167'>      8.1.2. Conditional Probability</a><br>
<a href='#concept_168'>      8.1.3. Unions and Intersections</a><br>
<a href='#concept_169'>      8.1.4. Complementary Events</a><br>
<br>
<a href='#section_34'>       8.3. Probability Rules</a><br>
<a href='#concept_170'>      8.3.1. The Addition Rule</a><br>
<a href='#concept_171'>      8.3.2. The Multiplication Rule</a><br>
<a href='#concept_172'>      8.3.3. Independence</a><br>
<a href='#concept_173'>      8.3.4. Counting Rules and Techniques</a><br>
<a href='#concept_174'>      8.3.5. Bayes' Rule</a><br>
<a href='#concept_175'>      8.3.6. The Collins Case</a><br>
<br>
<a href='#section_35'>       8.3. More About Chance</a><br>
<a href='#concept_176'>      8.3.1. The Paradox of the Chevalier De Méré</a><br>
<a href='#concept_177'>      8.3.2. Are Real Dice Fair?</a><br>
</div>

<h1 id='chapter_8'>8. Probability</h1>

<h2 id='section_33'>8.1. What Are the Chances?</h2>

<h3 id='concept_166'>8.1.1. Fundamentals of Probability</h3>

<blockquote>Probability is the branch of mathematics that deals with the likelihood that certain outcomes will occur.  There are five basic rules, or axioms, that one must understand while studying the fundamentals of probability.</blockquote>

<h4>Learning Objective</h4>

<p>Explain the most basic and most important rules in determining the probability of an event</p>

<h4>Key Points</h4>

<ul>
<li>Probability is a number that can be assigned to outcomes and events. It always is greater than or equal to zero, and less than or equal to one.</li>
<li>The sum of the probabilities of all outcomes must equal <span class='clFormula'>$1$</span>
.</li>
<li>If two events have no outcomes in common, the probability that one or the other occurs is the sum of their individual probabilities.</li>
<li>The probability that an event does not occur is <span class='clFormula'>$1$</span>
minus the probability that the event does occur.</li>
<li>Two events <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
are independent if knowing that one occurs does not change the probability that the other occurs.</li>
</ul>

<h4>Key Terms</h4>

<dl>
<dt>experiment</dt>
<dd>Something that is done that produces measurable results, called outcomes.</dd>
<dt>outcome</dt>
<dd>One of the individual results that can occur in an experiment.</dd>
<dt>event</dt>
<dd>A subset of the sample space.</dd>
<dt>sample space</dt>
<dd>The set of all outcomes of an experiment.</dd>
</dl>

<p>In discrete probability, we assume a well-defined experiment, such as flipping a coin or rolling a die. Each individual result which could occur is called an <em>outcome</em>. The set of all outcomes is called the sample space, and any subset of the sample space is called an <em>event. </em></p>
<p>For example, consider the experiment of flipping a coin two times. There are four individual outcomes, namely <span class='clFormula'>$HH, HT, TH, TT.$</span>
The sample space is thus <span class='clFormula'>$\{HH, HT, TH, TT\}.$</span>
The event "at least one heads occurs" would be the set <span class='clFormula'>$\{HH, HT, TH\}.$</span>
If the coin were a normal coin, we would assign the probability of <span class='clFormula'>$1/4$</span>
 to each outcome. </p>
<p>In probability theory, the probability <span class='clFormula'>$P$</span>
of some event <span class='clFormula'>$E$</span>
, denoted <span class='clFormula'>$P(E)$</span>
, is usually defined in such a way that <span class='clFormula'>$P$</span>
satisfies a number of axioms, or rules. The most basic and most important rules are listed below.</p>

<h3>Probability Rules</h3>


<ol>
<li>
<em>Probability is a number. It is always greater than or equal to zero, and less than or equal to one</em>.  This can be written as <span class='clFormula'>$0 \leq P(A) \leq 1$</span>
.  An impossible event, or an event that never occurs, has a probability of <span class='clFormula'>$0$</span>
. An event that always occurs has a probability of <span class='clFormula'>$1$</span>
. An event with a probability of <span class='clFormula'>$0.5$</span>
will occur half of the time. </li>
<li>
<em>The sum of the probabilities of all possibilities must equal </em><span class='clFormula'>$1$</span>
. Some outcome must occur on every trial, and the sum of all probabilities is 100%, or in this case, <span class='clFormula'>$1$</span>
. This can be written as <span class='clFormula'>$P(S) = 1$</span>
, where <span class='clFormula'>$S$</span>
represents the entire sample space.</li>
<li>
<em>If two events have no outcomes in common, the probability that one or the other occurs is the sum of their individual probabilities</em>. If one event occurs in <span class='clFormula'>$30\%$</span>
of the trials, a different event occurs in <span class='clFormula'>$20\%$</span>
of the trials, and the two cannot occur together (if they are disjoint), then the probability that one or the other occurs is <span class='clFormula'>$30\% + 20\% = 50\%$</span>
. This is sometimes referred to as the addition rule, and can be simplified with the following: <span class='clFormula'>$P(A \ \text{or} \ B) = P(A)+P(B)$</span>
. The word "or" means the same thing in mathematics as the union, which uses the following symbol: <span class='clFormula'>$\cup&#10;$</span>
. Thus when <span class='clFormula'>$A$</span>
 and <span class='clFormula'>$B$</span>
are disjoint, we have <span class='clFormula'>$P(A \cup B) = P(A)+P(B)$</span>
.</li>
<li>
<em>The probability that an event does not occur is </em><span class='clFormula'>$1$</span><em> minus the probability that the event does occur</em>. If an event occurs in <span class='clFormula'>$60\%$</span>
of all trials, it fails to occur in the other <span class='clFormula'>$40\%$</span>
, because <span class='clFormula'>$100\% - 60\% = 40\%$</span>
. The probability that an event occurs and the probability that it does not occur always add up to <span class='clFormula'>$100\%$</span>
, or <span class='clFormula'>$1$</span>
. These events are called complementary events, and this rule is sometimes called the complement rule. It can be simplified with <span class='clFormula'>$P(A^c) = 1-P(A)$</span>
, where <span class='clFormula'>$A^c$</span>
is the complement of <span class='clFormula'>$A$</span>
.</li>
<li>
<em>Two events </em><span class='clFormula'>$A$</span><em> and </em><span class='clFormula'>$B$</span><em> are independent if knowing that one occurs does not change the probability that the other occurs</em>. This is often called the multiplication rule. If <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
are independent, then <span class='clFormula'>$P(A \ \text{and} \ B) = P(A)P(B)$</span>
. The word "and" in mathematics means the same thing in mathematics as the intersection, which uses the following symbol: <span class='clFormula'>$\cap$</span>
. Therefore when A and B are independent, we have <span class='clFormula'>$P(A \cap B) = P(A)P(B).$</span></li>
</ol>

<h3>Extension of the Example</h3>

<p>Elaborating on our example above of flipping two coins, assign the probability <span class='clFormula'>$1/4$</span>
to each of the <span class='clFormula'>$4$</span>
outcomes. We consider each of the five rules above in the context of this example.</p>
<p>1. Note that each probability is <span class='clFormula'>$1/4$</span>
, which is between <span class='clFormula'>$0$</span>
and <span class='clFormula'>$1$</span>
.</p>
<p>2. Note that the sum of all the probabilities is <span class='clFormula'>$1$</span>
, since  <span class='clFormula'>$\frac{1}{4}+\frac{1}{4}+\frac{1}{4}+\frac{1}{4}=1&#10;$</span>
.</p>
<p>3. Suppose <span class='clFormula'>$A$</span>
is the event exactly one head occurs, and <span class='clFormula'>$B$</span>
is the event exactly two tails occur. Then <span class='clFormula'>$A=\{HT,TH\}$</span>
and <span class='clFormula'>$B=\{TT\}$</span>
are disjoint. Also, <span class='clFormula'>$P(A \cup B) = \frac{3}{4} = \frac{2}{4}+\frac{1}{4}=P(A) + P(B).$</span></p>
<p>4. The probability that no heads occurs is <span class='clFormula'>$1/4$</span>
, which is equal to  <span class='clFormula'>$1-3/4$</span>
. So if <span class='clFormula'>$A=\{HT, TH, HH\}$</span>
is the event that a head occurs, we have <span class='clFormula'>$P(A^c)=\frac{1}{4}=1 - \frac{3}{4}=1-P(A).$</span></p>
<p>5. If <span class='clFormula'>$A$</span>
is the event that the first flip is a heads and <span class='clFormula'>$B$</span>
is the event that the second flip is a heads, then <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
are independent. We have <span class='clFormula'>$A=\{HT,HH\}$</span>
and <span class='clFormula'>$B=\{TH,HH\}$</span>
and  <span class='clFormula'>$A \cap B = \{HH\}.$</span>
Note that <span class='clFormula'>$P(A \cap B) = \frac{1}{4} =\frac{1}{2}\cdot \frac{1}{2} = P(A)P(B).$</span></p>



<a href='../images/18070.png'><img class='clImageThumb' src='../images/18070.png' alt='Die'></a>

<div><b><i>Die</i></b></div>
<p><i>Dice are often used when learning the rules of probability.</i></p>

<h3 id='concept_167'>8.1.2. Conditional Probability</h3>

<blockquote>The conditional probability of an event is the probability that an event will occur given that another event has occurred.</blockquote>

<h4>Learning Objective</h4>

<p>Explain the significance of Bayes' theorem in manipulating conditional probabilities</p>

<h4>Key Points</h4>

<ul>
<li>The conditional probability <span class='clFormula'>$P(B \vert A)$</span>
of an event <span class='clFormula'>$B$</span>
, given an event <span class='clFormula'>$A$</span>
, is defined by: <span class='clFormula'>$P(B|A)=\frac{P(A\cap B)}{P(A)}$</span>
, when <span class='clFormula'>$P(A) &gt; 0$</span>
.</li>
<li>If the knowledge that event <span class='clFormula'>$A$</span>
occurs does not change the probability that event <span class='clFormula'>$B$</span>
occurs, then <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
are independent events, and thus, <span class='clFormula'>$P(B|A) = P(B)$</span>
.</li>
<li>Mathematically, Bayes' theorem gives the relationship between the probabilities of <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
, <span class='clFormula'>$P(A)$</span>
and <span class='clFormula'>$P(B)$</span>
, and the conditional probabilities of <span class='clFormula'>$A$</span>
given <span class='clFormula'>$B$</span>
and <span class='clFormula'>$B$</span>
given <span class='clFormula'>$A$</span>
, <span class='clFormula'>$P(A|B)$</span>
and <span class='clFormula'>$P(B|A)$</span>
. In its most common form, it is: <span class='clFormula'>$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$</span>
.</li>
</ul>

<h4>Key Terms</h4>

<dl>
<dt>conditional probability</dt>
<dd>The probability that an event will take place given the restrictive assumption that another event has taken place, or that a combination of other events has taken place</dd>
<dt>independent</dt>
<dd>Not dependent; not contingent or depending on something else; free.</dd>
</dl>

<h3>Probability of <span class='clFormula'>$B$</span>
 Given That <span class='clFormula'>$A$</span>
 Has Occurred</h3>

<p>Our estimation of the likelihood of an event can change if we know that some other event has occurred.  For example, the probability that a rolled die  shows a <span class='clFormula'>$2$</span>
is <span class='clFormula'>$1/6$</span>
without any other information, but if someone looks at the die and tells you that is is an even number, the probability is now <span class='clFormula'>$1/3$</span>
 that it is a <span class='clFormula'>$2$</span>
. The notation <span class='clFormula'>$P(B|A)$</span>
indicates a conditional probability, meaning it indicates the probability of one event under the condition that we know another event has happened. The bar "|" can be read as "given", so that <span class='clFormula'>$P(B|A)$</span>
is read as "the probability of <span class='clFormula'>$B$</span>
given that <span class='clFormula'>$A$</span>
has occurred".</p>
<p>The conditional probability <span class='clFormula'>$\displaystyle P(B|A)$</span>
 of an event <span class='clFormula'>$B$</span>
, given an event <span class='clFormula'>$A$</span>
, is defined by:</p>
<p><span class='clFormula'>$\displaystyle P(B|A)=\frac{P(A\cap B)}{P(A)}$</span>
 </p>
<p>When <span class='clFormula'>$P(A) &gt; 0$</span>
. Be sure to remember the distinct roles of <span class='clFormula'>$B$</span>
and <span class='clFormula'>$A$</span>
in this formula. The set after the bar is the one we are assuming has occurred, and its probability occurs in the denominator of the formula.  </p>

<h3>Example</h3>

<p>Suppose that a coin is flipped 3 times giving the sample space:</p>
<p> <span class='clFormula'>$S=\{HHH, HHT, HTH, THH, TTH, THT, HTT, TTT\}$</span>
 </p>
<p>Each individual outcome has probability <span class='clFormula'>$1/8$</span>
. Suppose that <span class='clFormula'>$B$</span>
is the event that at least one heads occurs and <span class='clFormula'>$A$</span>
is the event that all <span class='clFormula'>$3$</span>
coins are the same. Then the probability of <span class='clFormula'>$B$</span>
given <span class='clFormula'>$A$</span>
is <span class='clFormula'>$1/2$</span>
, since <span class='clFormula'>$A \cap B=\{HHH\}$</span>
which has probability <span class='clFormula'>$1/8$</span>
 and <span class='clFormula'>$A=\{HHH,TTT\}$</span>
which has probability <span class='clFormula'>$2/8$</span>
, and <span class='clFormula'>$\frac{1/8}{2/8}=\frac{1}{2}.$</span></p>

<h3>
Independence
</h3>

<p>The conditional probability <span class='clFormula'>$P(B|A)$</span>
is not always equal to the unconditional probability <span class='clFormula'>$P(B)$</span>
. The reason behind this is that the occurrence of event <span class='clFormula'>$A$</span>
 may provide extra information that can change the probability that event <span class='clFormula'>$B$</span>
occurs. If the knowledge that event <span class='clFormula'>$A$</span>
occurs does not change the probability that event <span class='clFormula'>$B$</span>
occurs, then <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
are independent events, and thus, <span class='clFormula'>$P(B|A) = P(B)$</span>
.</p>

<h3>Bayes' Theorem</h3>

<p>In probability theory and statistics, Bayes' theorem (alternatively Bayes' law or Bayes' rule) is a result that is of importance in the mathematical manipulation of conditional probabilities. It can be derived from the basic axioms of probability.</p>
<p>Mathematically, Bayes' theorem gives the relationship between the probabilities of <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
, <span class='clFormula'>$P(A)$</span>
and <span class='clFormula'>$P(B)$</span>
, and the conditional probabilities of <span class='clFormula'>$A$</span>
given <span class='clFormula'>$B$</span>
and <span class='clFormula'>$B$</span>
given <span class='clFormula'>$A$</span>
. In its most common form, it is:</p>

<div class='clFormula'>$\displaystyle P(A|B)=\frac{P(B|A)P(A)}{P(B)}$</div>

<p>This may be easier to remember in this alternate symmetric form: </p>

<div class='clFormula'>$\displaystyle \frac{P(A|B)}{P(B|A)}=\frac{P(A)}{P(B)}$</div>


<h3>Example:</h3>

<p>Suppose someone told you they had a nice conversation with someone on the train. Not knowing anything else about this conversation, the probability that they were speaking to a woman is <span class='clFormula'>$50\%$</span>
. Now suppose they also told you that this person had long hair. It is now more likely they were speaking to a woman, since women in in this city are more likely to have long hair than men. Bayes's theorem can be used to calculate the probability that the person is a woman.</p>
<p>To see how this is done, let <span class='clFormula'>$W$</span>
represent the event that the conversation was held with a woman, and <span class='clFormula'>$L$</span>
denote the event that the conversation was held with a long-haired person. It can be assumed that women constitute half the population for this example. So, not knowing anything else, the probability that <span class='clFormula'>$W$</span>
occurs is <span class='clFormula'>$P(W) = 0.5$</span>
.</p>
<p>Suppose it is also known that <span class='clFormula'>$75\%$</span>
of women in this city have long hair, which we denote as <span class='clFormula'>$P(L|W) = 0.75$</span>
. Likewise, suppose it is known that <span class='clFormula'>$25\%$</span>
of men in this city have long hair, or <span class='clFormula'>$P(L|M) = 0.25$</span>
, where <span class='clFormula'>$M$</span>
is the complementary event of <span class='clFormula'>$W$</span>
, i.e., the event that the conversation was held with a man (assuming that every human is either a man or a woman).</p>
<p>Our goal is to calculate the probability that the conversation was held with a woman, given the fact that the person had long hair, or, in our notation, <span class='clFormula'>$P(W|L)$</span>
. Using the formula for Bayes's theorem, we have:</p>

<div class='clFormula'>$\displaystyle &#10;\begin{align}&#10;P(W|L) &amp;= \frac{P(L|W)P(W)}{P(L)}\\&#10;&amp;= \frac{P(L|W)P(W)}{P(L|W)P(W)+P(L|M)P(M)}\\&#10;&amp;=\frac{0.75\cdot 0.5}{0.75\cdot 0.5+0.25\cdot 0.5}\\&#10;&amp;=0.75&#10;\end{align}$</div>


<h3 id='concept_168'>8.1.3. Unions and Intersections</h3>

<blockquote>Union and intersection are two key concepts in set theory and probability.</blockquote>

<h4>Learning Objective</h4>

<p>Give examples of the intersection and the union of two or more sets</p>

<h4>Key Points</h4>

<ul>
<li>The union of two or more sets is the set that contains all the elements of the two or more sets. Union is denoted by the symbol <span class='clFormula'>$\cup$</span>
.</li>
<li>The general probability addition rule for the union of two events states that <span class='clFormula'>$P(A\cup B) = P(A)+P(B)-P(A \cap B)$</span>
, where <span class='clFormula'>$A \cap B$</span>
is the intersection of the two sets.</li>
<li>The addition rule can be shortened if the sets are disjoint: <span class='clFormula'>$P(A \cup B) = P(A) + P(B)$</span>
. This can even be extended to more sets if they are all disjoint: <span class='clFormula'>$P(A \cup B \cup C) = P(A) + P(B) + P(C)$</span>
.</li>
<li>The intersection of two or more sets is the set of elements that are common to every set. The symbol <span class='clFormula'>$\cap$</span>
is used to denote the intersection.</li>
<li>When events are independent, we can use the multiplication rule for independent events, which states that <span class='clFormula'>$P(A \cap B) = P(A)P(B)$</span>
.</li>
</ul>

<h4>Key Terms</h4>

<dl>
<dt>independent</dt>
<dd>Not contingent or dependent on something else.</dd>
<dt>disjoint</dt>
<dd>Having no members in common; having an intersection equal to the empty set.</dd>
</dl>

<h3>Introduction</h3>

<p>Probability uses the mathematical ideas of sets, as we have seen in the definition of both the sample space of an experiment and in the definition of an event. In order to perform basic probability calculations, we need to review the ideas from set theory related to the set operations of union, intersection, and complement. </p>

<h3>Union</h3>

<p>The union of two or more sets is the set that contains all the elements of each of the sets; an element is in the union if it belongs to at least one of the sets. The symbol for union is <span class='clFormula'>$\cup$</span>
, and is associated with the word "or", because <span class='clFormula'>$A \cup B$</span>
  is the set of all elements that are in <span class='clFormula'>$A$</span>
or <span class='clFormula'>$B$</span>
(or both.) To find the union of two sets, list the elements that are in either (or both) sets. In terms of a Venn Diagram, the union of sets <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
can be shown as two completely shaded interlocking circles.</p>



<a href='../images/18075.svg'><img class='clImageThumb' src='../images/18075.svg' alt='Union of Two Sets'></a>

<div><b><i>Union of Two Sets</i></b></div>
<p>The shaded Venn Diagram shows the union of set <span class='clFormula'>$A$</span>
(the circle on left) with set <span class='clFormula'>$B$</span>
(the circle on the right). It can be written shorthand as <span class='clFormula'>$A \cup B$</span>.</p>

<p>In symbols, since the union of <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
contains all the points that are in <span class='clFormula'>$A$</span>
or <span class='clFormula'>$B$</span>
or both, the definition of the union is:</p>

<div class='clFormula'>$\displaystyle&#10;A \cup B = \{x: x\in A \ \text{or} \ x\in B \}$</div>

<p>For example, if <span class='clFormula'>$A = \{1, 3, 5, 7\}$</span>
 and <span class='clFormula'>$B = \{1, 2, 4, 6\}$</span>
 , then <span class='clFormula'>$A \cup B = \{1, 2, 3, 4, 5, 6, 7\}$</span>
. Notice that the element <span class='clFormula'>$1$</span>
is not listed twice in the union, even though it appears in both sets <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
. This leads us to the general addition rule for the union of two events: </p>

<div class='clFormula'>$\displaystyle&#10;P(A \cup B) = P(A) + P(B) - P(A \cap B)$</div>

<p>Where <span class='clFormula'>$P(A\cap B)$</span>
is the intersection of the two sets. We must subtract this out to avoid double counting of the inclusion of an element.</p>
<p>If sets <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
are disjoint, however, the event <span class='clFormula'>$A \cap B$</span>
has no outcomes in it, and is an empty set denoted as <span class='clFormula'>$\emptyset$</span>
, which has a probability of zero. So, the above rule can be shortened for disjoint sets only: </p>

<div class='clFormula'>$\displaystyle&#10;P(A \cup B) = P(A)+P(B)$</div>

<p>This can even be extended to more sets if they are all disjoint: </p>

<div class='clFormula'>$\displaystyle&#10;P(A \cup B \cup C) = P(A) + P(B)+ P(C)$</div>


<h3>Intersection</h3>

<p>The intersection of two or more sets is the set of elements that are common to each of the sets. An element is in the intersection if it belongs to all of the sets. The symbol for intersection is <span class='clFormula'>$\cap$</span>
, and is associated with the word "and", because <span class='clFormula'>$A \cap B$</span>
  is the set of elements that are in <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
simultaneously. To find the intersection of two (or more) sets, include only those elements that are listed in both (or all) of the sets. In terms of a Venn Diagram, the intersection of two sets <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
can be shown at the shaded region in the middle of two interlocking circles .</p>



<a href='../images/18076.svg'><img class='clImageThumb' src='../images/18076.svg' alt='Intersection of Two Sets'></a>

<div><b><i>Intersection of Two Sets</i></b></div>
<p>Set <span class='clFormula'>$A$</span>
is the circle on the left, set <span class='clFormula'>$B$</span>
is the circle on the right, and the intersection of <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
, or <span class='clFormula'>$A \cap B$</span>
, is the shaded portion in the middle.</p>

<p>In mathematical notation, the intersection of <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
is written as <span class='clFormula'>$A \cap B = \{x: x \in A \ \text{and} \ x \in B\}$</span>
. For example, if <span class='clFormula'>$A = \{1, 3, 5, 7\}$</span>
and <span class='clFormula'>$B = \{1, 2, 4, 6\}$</span>
, then <span class='clFormula'>$A \cap B = \{1\}$</span>
because <span class='clFormula'>$1$</span>
is the only element that appears in both sets <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
.</p>
<p>When events are independent, meaning that the outcome of one event doesn't affect the outcome of another event, we can use the multiplication rule for independent events, which states: </p>

<div class='clFormula'>$\displaystyle&#10;P(A \cap B)= P(A)P(B)$</div>

<p>For example, let's say we were tossing a coin twice, and we want to know the probability of tossing two heads. Since the first toss doesn't affect the second toss, the events are independent. Say  is the event that the first toss is a heads and <span class='clFormula'>$B$</span>
is the event that the second toss is a heads, then <span class='clFormula'>$P(A \cap B) = \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{4}$</span>
.</p>

<h3 id='concept_169'>8.1.4. Complementary Events</h3>

<blockquote>The complement of <span class='clFormula'>$A$</span>
is the event in which <span class='clFormula'>$A$</span>
does not occur.</blockquote>

<h4>Learning Objective</h4>

<p>Explain an example of a complementary event</p>

<h4>Key Points</h4>

<ul>
<li>The complement of an event <span class='clFormula'>$A$</span>
is usually denoted as <span class='clFormula'>$A'$</span>
, <span class='clFormula'>$A^c$</span>
or <span class='clFormula'>$\bar{A}$</span>
.</li>
<li>An event and its complement are mutually exclusive, meaning that if one of the two events occurs, the other event cannot occur.</li>
<li>An event and its complement are exhaustive, meaning that both events cover all possibilities.</li>
</ul>

<h4>Key Terms</h4>

<dl>
<dt>exhaustive</dt>
<dd>including every possible element</dd>
<dt>mutually exclusive</dt>
<dd>describing multiple events or states of being such that the occurrence of any one implies the non-occurrence of all the others</dd>
</dl>

<h3>What are Complementary Events?</h3>

<p>In probability theory, the complement of any event <span class='clFormula'>$A$</span>
is the event <span class='clFormula'>$[\text{not}\ A]$</span>
, i.e. the event in which <span class='clFormula'>$A$</span>
does not occur. The event <span class='clFormula'>$A$</span>
and its complement <span class='clFormula'>$[\text{not}\ A]$</span>
are mutually exclusive and exhaustive, meaning that if one occurs, the other does not, and that both groups cover all possibilities. Generally, there is only one event <span class='clFormula'>$B$</span>
such that  <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
are both mutually exclusive and exhaustive; that event is the complement of <span class='clFormula'>$A$</span>
. The complement of an event <span class='clFormula'>$A$</span>
 is usually denoted as <span class='clFormula'>$A'$</span>
, <span class='clFormula'>$A^c$</span>
 or <span class='clFormula'>$\bar{A}$</span>
.</p>

<h3>Simple Examples</h3>

<p>A common example used to demonstrate complementary events is the flip of a coin. Let's say a coin is flipped and one assumes it cannot land on its edge. It can either land on heads or on tails. There are no other possibilities (exhaustive), and both events cannot occur at the same time (mutually exclusive). Because these two events are complementary, we know that <span class='clFormula'>$P(\text{heads}) + P(\text{tails}) = 1$</span>
.</p>



<a href='../images/18067.jpeg'><img class='clImageThumb' src='../images/18067.jpeg' alt='Coin Flip'></a>

<div><b><i>Coin Flip</i></b></div>
<p>Often in sports games, such as tennis, a coin flip is used to determine who will serve first because heads and tails are complementary events.</i></p>

<p>Another simple example of complementary events is picking a ball out of a bag. Let's say there are three plastic balls in a bag. One is blue and two are red. Assuming that each ball has an equal chance of being pulled out of the bag, we know that <span class='clFormula'>$P(\text{blue}) = \frac{1}{3}$</span>
and <span class='clFormula'>$P(\text{red}) = \frac{2}{3}$</span>
. Since we can only either chose blue or red (exhaustive) and we cannot choose both at the same time (mutually exclusive), choosing blue and choosing red are complementary events, and <span class='clFormula'>$P(\text{blue}) + P(\text{red}) = 1$</span>
.</p>
<p>Finally, let's examine a non-example of complementary events. If you were asked to choose any number, you might think that that number could either be prime or composite. Clearly, a number cannot be both prime and composite, so that takes care of the mutually exclusive property. However, being prime or being composite are not exhaustive because the number 1 in mathematics is designated as "unique. "</p>
<h2 id='section_34'>8.2. Probability Rules</h2>

<h3 id='concept_170'>8.2.1. The Addition Rule</h3>

<blockquote>The addition rule states the probability of two events is the sum of the probability that either will happen minus the probability that both will happen.</blockquote>

<h4>Learning Objective</h4>

<p>Calculate the probability of an event using the addition rule</p>

<h4>Key Points</h4>

<ul>
<li>The addition rule is: <span class='clFormula'>$P(A\cup B)=P(A)+P(B)-P(A\cap B).$</span></li>
<li>The last term has  been accounted for twice, once in <span class='clFormula'>$P(A)$</span>
and once in <span class='clFormula'>$P(B)$</span>
, so it must be subtracted once so that it is not double-counted.</li>
<li>If <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
are disjoint, then <span class='clFormula'>$P(A\cap B)=0$</span>
, so the formula becomes <span class='clFormula'>$P(A \cup B)=P(A) + P(B).$</span></li>
</ul>

<h4>Key Term</h4>

<dl>
<dt>probability</dt>
<dd>The relative likelihood of an event happening.</dd>
</dl>

<h3>Addition Law</h3>

<p>The addition law of probability (sometimes referred to as the addition rule or sum rule), states that the probability that <span class='clFormula'>$A$</span>
or <span class='clFormula'>$B$</span>
will occur is the sum of the probabilities that <span class='clFormula'>$A$</span>
will happen and that <span class='clFormula'>$B$</span>
will happen, minus the probability that both <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
will happen. The addition rule is summarized by the formula:</p>

<div class='clFormula'>$\displaystyle&#10;P(A \cup B) = P(A)+P(B)-P(A \cap B)$</div>

<p>Consider the following example. When drawing one card out of a deck of <span class='clFormula'>$52$</span>
playing cards, what is the probability of getting heart or a face card (king, queen, or jack)? Let <span class='clFormula'>$H$</span>
denote drawing a heart and <span class='clFormula'>$F$</span>
denote drawing a face card. Since there are <span class='clFormula'>$13$</span>
hearts and a total of <span class='clFormula'>$12$</span>
face cards (<span class='clFormula'>$3$</span>
of each suit: spades, hearts, diamonds and clubs), but only <span class='clFormula'>$3$</span>
 face cards of hearts, we obtain:</p>

<div class='clFormula'>$\displaystyle P(H) = \frac{13}{52}$</div>


<div class='clFormula'>$\displaystyle P(F) = \frac{12}{52}$</div>


<div class='clFormula'>$\displaystyle P(F \cap H) = \frac{3}{52}$</div>

<p>Using the addition rule, we get:</p>

<div class='clFormula'>$\displaystyle &#10;\begin{align}&#10;P(H\cup F)&amp;=P(H)+P(F)-P(H\cap F)\\&#10;&amp;=\frac { 13 }{ 52 } +\frac { 12 }{ 52 } -\frac { 3 }{ 52 }&#10;\end{align}$</div>

<p>The reason for subtracting the last term is that otherwise we would be counting the middle section twice (since <span class='clFormula'>$H$</span>
and <span class='clFormula'>$F$</span>
overlap). </p>

<h3>Addition Rule for Disjoint Events</h3>

<p>Suppose <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
are disjoint, their intersection is empty. Then the probability of their intersection is zero. In symbols: <span class='clFormula'>$P(A \cap B) = 0$</span>
. The addition law then simplifies to:</p>
<p><span class='clFormula'>$P(A \cup B) = P(A) + P(B) \qquad \text{when} \qquad A \cap B = \emptyset$</span>
 </p>
<p>The symbol <span class='clFormula'>$\emptyset$</span>
represents the empty set, which indicates that in this case <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
do not have any elements in common (they do not overlap).</p>

<h3>Example:</h3>

<p>Suppose a card is drawn from a deck of 52 playing cards: what is the probability of getting a king or a queen? Let <span class='clFormula'>$A$</span>
represent the event that a king is drawn and <span class='clFormula'>$B$</span>
represent the event that a queen is drawn. These two events are disjoint, since there are no kings that are also queens. Thus:</p>

<div class='clFormula'>$\displaystyle&#10;\begin{align}&#10;P(A \cup B) &amp;= P(A) + P(B)\\&amp;=\frac{4}{52}+\frac{4}{52}\\&amp;=\frac{8}{52}\\&amp;=\frac{2}{13}&#10;\end{align}$</div>


<h3 id='concept_171'>8.2.2. The Multiplication Rule</h3>

<blockquote>The multiplication rule states that the probability that <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
both occur is equal to the probability that <span class='clFormula'>$B$</span>
occurs times the conditional probability that <span class='clFormula'>$A$</span>
occurs given that <span class='clFormula'>$B$</span>
occurs.</blockquote>

<h4>Learning Objective</h4>

<p>Apply the multiplication rule to calculate the probability of both <equation>$A$</equation> and <equation>$B$</equation> occurring</p>

<h4>Key Points</h4>

<ul>
<li> The multiplication rule can be written as: <span class='clFormula'>$P(A \cap B) = P(B) \cdot P(A|B)$</span>
.</li>
<li>We obtain the general multiplication rule by multiplying both sides of the definition of conditional probability by the denominator.</li>
</ul>

<h4>Key Term</h4>

<dl>
<dt>sample space</dt>
<dd>The set of all possible outcomes of a game, experiment or other situation.</dd>
</dl>

<h3>The Multiplication Rule</h3>

<p>In probability theory, the Multiplication Rule states that the probability that <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
occur is equal to the probability that <span class='clFormula'>$A$</span>
occurs times the conditional probability that <span class='clFormula'>$B$</span>
occurs, given that we know <span class='clFormula'>$A$</span>
has already occurred. This rule can be written:</p>

<div class='clFormula'>$\displaystyle&#10;P(A \cap B) = P(B) \cdot P(A|B)$</div>

<p>Switching the role of <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
, we can also write the rule  as:</p>

<div class='clFormula'>$\displaystyle&#10;P(A\cap B) = P(A) \cdot P(B|A)$</div>

<p>We obtain the general multiplication rule by multiplying both sides of the definition of conditional probability by the denominator. That is, in the equation <span class='clFormula'>$\displaystyle P(A|B)=\frac{P(A\cap B)}{P(B)}$</span>
, if we multiply both sides by <span class='clFormula'>$P(B)$</span>
, we obtain the Multiplication Rule. </p>
<p>The rule is useful when we know both <span class='clFormula'>$P(B)$</span>
 and <span class='clFormula'>$P(A|B)$</span>
, or both <span class='clFormula'>$P(A)$</span>
 and <span class='clFormula'>$P(B|A).$</span></p>

<h3>Example</h3>

<p>Suppose that we draw two cards out of a deck of cards and let <span class='clFormula'>$A$</span>
 be the event the the first card is an ace, and <span class='clFormula'>$B$</span>
 be the event that the second card is an ace, then:</p>

<div class='clFormula'>$\displaystyle P(A)=\frac { 4 }{ 52 }$</div>

<p>And:</p>

<div class='clFormula'>$\displaystyle P\left( { B }|{ A } \right) =\frac { 3 }{ 51 }$</div>

<p>The denominator in the second equation is <span class='clFormula'>$51$</span>
since we know a card has already been drawn. Therefore, there are <span class='clFormula'>$51$</span>
left in total. We also know the first card was an ace, therefore:</p>

<div class='clFormula'>$\displaystyle&#10;\begin{align}&#10;P(A \cap B) &amp;= P(A) \cdot P(B|A)\\&#10;&amp;= \frac { 4 }{ 52 } \cdot \frac { 3 }{ 51 } \\&#10;&amp;=0.0045&#10;\end{align}$</div>


<h3>Independent Event</h3>

<p>Note that when <span class='clFormula'>$A$</span>
 and <span class='clFormula'>$B$</span>
 are independent, we have that <span class='clFormula'>$P(B|A)= P(B)$</span>
, so the formula becomes <span class='clFormula'>$P(A \cap B)=P(A)P(B)$</span>
, which we encountered in a previous section. As an example, consider the experiment of rolling a die and flipping a coin. The probability that we get a <span class='clFormula'>$2$</span>
on the die and a tails on the coin is <span class='clFormula'>$\frac{1}{6}\cdot \frac{1}{2} = \frac{1}{12}$</span>
, since the two events are independent.  </p>

<h3 id='concept_172'>8.2.3. Independence</h3>

<blockquote>To say that two events are independent means that the occurrence of one does not affect the probability of the other.</blockquote>

<h4>Learning Objective</h4>

<p>Explain the concept of independence in relation to probability theory</p>

<h4>Key Points</h4>

<ul>
<li>Two events are independent if the following are true: <span class='clFormula'>$P(A|B) = P(A)$</span>
,<span class='clFormula'>$P(B|A) = P(B)$</span>
, and <span class='clFormula'>$P(A \ \text{and} \ B) = P(A) \cdot P(B)$</span>
.</li>
<li>If any one of these conditions is true, then all of them are true.</li>
<li>If events <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
are independent, then the chance of <span class='clFormula'>$A$</span>
occurring does not affect the chance of <span class='clFormula'>$B$</span>
occurring and vice versa.</li>
</ul>

<h4>Key Terms</h4>

<dl>
<dt>independence</dt>
<dd>The occurrence of one event does not affect the probability of the occurrence of another.</dd>
<dt>probability theory</dt>
<dd>The mathematical study of probability (the likelihood of occurrence of random events in order to predict the behavior of defined systems).</dd>
</dl>

<h3>Independent Events</h3>

<p>In probability theory, to say that two events are independent means that the occurrence of one does not affect the probability that the other will occur. In other words, if events <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
are independent, then the chance of <span class='clFormula'>$A$</span>
occurring does not affect the chance of <span class='clFormula'>$B$</span>
occurring and vice versa. The concept of independence extends to dealing with collections of more than two events.</p>
<p>Two events are independent if any of the following are true:</p>

<ol>
<li>
<span class='clFormula'>$\displaystyle P(A|B) = P(A)$</span></li>
<li>
<span class='clFormula'>$\displaystyle P(B|A) = P(B)$</span></li>
<li>
<span class='clFormula'>$\displaystyle P(A \ \text{and} \ B) = P(A)\cdot P(B)$</span></li>
</ol>
<p>To show that two events are independent, you must show only one of the conditions listed above. If any one of these conditions is true, then all of them are true.</p>
<p>Translating the symbols into words, the first two mathematical statements listed above say that the probability for the event with the condition is the same as the probability for the event without the condition. For independent events, the condition does not change the probability for the event. The third statement says that the probability of both independent events <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
occurring is the same as the probability of <span class='clFormula'>$A$</span>
occurring, multiplied by the probability of <span class='clFormula'>$B$</span>
occurring.</p>
<p>As an example, imagine you select two cards consecutively from a complete deck of playing cards. The two selections are not independent. The result of the first selection changes the remaining deck and affects the probabilities for the second selection. This is referred to as selecting "without replacement" because the first card has not been replaced into the deck before the second card is selected.</p>
<p>However, suppose you were to select two cards "with replacement" by returning your first card to the deck and shuffling the deck before selecting the second card. Because the deck of cards is complete for both selections, the first selection does not affect the probability of the second selection. When selecting cards with replacement, the selections are independent.</p>



<a href='../images/18071.jpeg'><img class='clImageThumb' src='../images/18071.jpeg' alt='Independent Events'></a>

<div><b><i>Independent Events</i></b></div>
<p><i>Selecting two cards from a deck by first selecting one, then replacing it in the deck before selecting a second is an example of independent events.</i></p>

<p>Consider a fair die role, which provides another example of independent events. If a person roles two die, the outcome of the first roll does not change the probability for the outcome of the second roll.</p>

<h3>Example</h3>

<p>Two friends are playing billiards, and decide to flip a coin to determine who will play first during each round. For the first two rounds, the coin lands on heads. They decide to play a third round, and flip the coin again. What is the probability that the coin will land on heads again?</p>
<p>First, note that each coin flip is an independent event. The side that a coin lands on does not depend on what occurred previously. </p>
<p>For any coin flip, there is a <span class='clFormula'>${\frac{1}{2}}$</span>
chance that the coin will land on heads. Thus, the probability that the coin will land on heads during the third round is <span class='clFormula'>${\frac{1}{2}}$</span>
.</p>

<h3>Example</h3>

<p>When flipping a coin, what is the probability of getting tails <span class='clFormula'>$5$</span>
times in a row?</p>
<p>Recall that each coin flip is independent, and the probability of getting tails is <span class='clFormula'>${\frac{1}{2}}$</span>
for any flip. Also recall that the following statement holds true for any two independent events A and B:</p>

<div class='clFormula'>$\displaystyle P(A \ \text{and} \ B) = P(A)\cdot P(B)$</div>

<p>Finally, the concept of independence extends to collections of more than <span class='clFormula'>$2$</span>
events.</p>
<p>Therefore, the probability of getting tails <span class='clFormula'>$4$</span>
times in a row is:</p>

<div class='clFormula'>$\displaystyle&#10;{\frac{1}{2}} \cdot {\frac{1}{2}} \cdot {\frac{1}{2}} \cdot {\frac{1}{2}} = {\frac{1}{16}}&#10;$</div>


<h3 id='concept_173'>8.2.4. Counting Rules and Techniques</h3>

<blockquote>Combinatorics is a branch of mathematics concerning the study of finite or countable discrete structures.</blockquote>

<h4>Learning Objective</h4>

<p>Describe the different rules and properties for combinatorics</p>

<h4>Key Points</h4>

<ul>
<li>The rule of sum (addition rule), rule of product (multiplication rule), and inclusion-exclusion principle are often used for enumerative purposes.</li>
<li>Bijective proofs are utilized to demonstrate that two sets have the same number of elements.</li>
<li>Double counting is a technique used to demonstrate that two expressions are equal. The pigeonhole principle often ascertains the existence of something or is used to determine the minimum or maximum number of something in a discrete context.</li>
<li>Generating functions and recurrence relations are powerful tools that can be used to manipulate sequences, and can describe if not resolve many combinatorial situations.</li>
<li>Double counting is a technique used to demonstrate that two expressions are equal.</li>
</ul>

<h4>Key Terms</h4>

<dl>
<dt>polynomial</dt>
<dd>An expression consisting of a sum of a finite number of terms: each term being the product of a constant coefficient and one or more variables raised to a non-negative integer power.</dd>
<dt>combinatorics</dt>
<dd>A branch of mathematics that studies (usually finite) collections of objects that satisfy specified criteria.</dd>
</dl>

<p>Combinatorics is a branch of mathematics concerning the study of finite or countable discrete structures. Combinatorial techniques are applicable to many areas of mathematics, and a knowledge of combinatorics is necessary to build a solid command of statistics. It involves the enumeration, combination, and permutation
of sets of elements and the mathematical relations that characterize
their properties.
</p>
<p>Aspects of combinatorics include: counting the structures of a given kind and size, deciding when certain criteria can be met, and constructing and analyzing objects meeting the criteria. Aspects also include finding "largest," "smallest," or "optimal" objects, studying combinatorial structures arising in an algebraic context, or applying algebraic techniques to combinatorial problems.</p>

<h3>Combinatorial Rules and Techniques</h3>

<p>Several useful combinatorial rules or combinatorial principles are commonly recognized and used. Each of these principles is used for a specific purpose. The rule of sum (addition rule), rule of product (multiplication rule), and inclusion-exclusion principle are often used for enumerative purposes. Bijective proofs are utilized to demonstrate that two sets have the same number of elements. Double counting is a method of showing that two expressions are equal. The pigeonhole principle often ascertains the existence of something or is used to determine the minimum or maximum number of something in a discrete context. Generating functions and recurrence relations are powerful tools that can be used to manipulate sequences, and can describe if not resolve many combinatorial situations. Each of these techniques is described in greater detail below.</p>

<h3>Rule of Sum</h3>

<p>The rule of sum is an intuitive principle stating that if there are <span class='clFormula'>$a$</span>
 possible ways to do something, and <span class='clFormula'>$b$</span>
possible ways to do another thing, and the two things can't both be done, then there are <span class='clFormula'>$a + b$</span>
total possible ways to do one of the things. More formally, the sum of the sizes of two disjoint sets is equal to the size of the union of these sets.</p>

<h3>Rule of Product</h3>

<p>The rule of product is another intuitive principle stating that if there are <span class='clFormula'>$a$</span>
ways to do something and <span class='clFormula'>$b$</span>
ways to do another thing, then there are <span class='clFormula'>$a \cdot b$</span>
ways to do both things.</p>

<h3>Inclusion-Exclusion Principle</h3>

<p>The inclusion-exclusion principle is a counting technique that is used to obtain the number of elements in a union of multiple sets.  This counting method ensures that elements that are present in more than one set in the union are not counted more than once. It considers the size of each set and the size of the intersections of the sets. The smallest example is when there are two sets: the number of elements in the union of <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
is equal to the sum of the number of elements in <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
, minus the number of elements in their intersection. See the diagram below for an example with three sets.</p>

<h3>Bijective Proof</h3>

<p>A bijective proof is a proof technique that finds a bijective function <span class='clFormula'>$f: A \rightarrow B$</span>
between two finite sets <span class='clFormula'>$A$</span>
and <span class='clFormula'>$B$</span>
, which proves that they have the same number of elements,  <span class='clFormula'>$|A| = |B|$</span>
. A bijective function is one in which there is a one-to-one correspondence between the elements of two sets. In other words, each element in set <span class='clFormula'>$B$</span>
is paired with exactly one element in set <span class='clFormula'>$A$</span>
. This technique is useful if we wish to know the size of <span class='clFormula'>$A$</span>
, but can find no direct way of counting its elements. If <span class='clFormula'>$B$</span>
is more easily countable, establishing a bijection from <span class='clFormula'>$A$</span>
to  <span class='clFormula'>$B$</span>
solves the problem. </p>

<h3>Double Counting</h3>

<p>Double counting is a combinatorial proof technique for showing that two expressions are equal. This is done by demonstrating that the two expressions are two different ways of counting the size of one set. In this technique, a finite set <span class='clFormula'>$X$</span>
is described from two perspectives, leading to two distinct expressions for the size of the set. Since both expressions equal the size of the same set, they equal each other.</p>

<h3>Pigeonhole Principle</h3>

<p>The pigeonhole principle states that if <span class='clFormula'>$a$</span>
items are each put into one of <span class='clFormula'>$b$</span>
boxes, where <span class='clFormula'>$a&gt;b$</span>
, then at least one of the boxes contains more than one item. This principle allows one to demonstrate the existence of some element in a set with some specific properties. For example, consider a set of three gloves. In such a set, there must be either two left gloves or two right gloves (or three of left or right). This is an application of the pigeonhole principle that yields information about the properties of the gloves in the set.</p>

<h3>Generating Function</h3>

<p>Generating functions can be thought of as polynomials with infinitely many terms whose coefficients correspond to the terms of a sequence. The (ordinary) generating function of a sequence <span class='clFormula'>$a_n$</span>
is given by:</p>
<p> <span class='clFormula'>$\displaystyle&#10;f(x) = \sum_{n=0}^{\infty} a_{n}x^{n}$</span></p>
<p>whose coefficients give the sequence <span class='clFormula'>$\left \{ a_{0}, a_{1}, a_{2}, ... \right \}$</span>
.</p>

<h3>Recurrence Relation</h3>

<p>A recurrence relation defines each term of a sequence in terms of the preceding terms. In other words, once one or more initial terms are given, each of the following terms of the sequence is a function of the preceding terms. </p>
<p>The Fibonacci sequence is one example of a recurrence relation. Each term of the Fibonacci sequence is given by <span class='clFormula'>$F_{n} = F_{n-1} + F_{n-2}$</span>
, with initial values <span class='clFormula'>$F_{0}=0$</span>
and <span class='clFormula'>$F_{1}=1$</span>
. Thus, the sequence of Fibonacci numbers begins: </p>

<div class='clFormula'>$\displaystyle&#10;0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, ...$</div>


<h3 id='concept_174'>8.2.5. Bayes' Rule</h3>

<blockquote>Bayes' rule expresses how a subjective degree of belief should rationally change to account for evidence.</blockquote>

<h4>Learning Objective</h4>

<p>Explain the importance of Bayes's theorem in mathematical manipulation of conditional probabilities</p>

<h4>Key Points</h4>

<ul>
<li>Bayes' rule relates the odds of event <span class='clFormula'>$A_1$</span>
 to event <span class='clFormula'>$A_2$</span>
, before (prior to) and after (posterior to) conditioning on another event <span class='clFormula'>$B$</span>
.</li>
<li>More specifically, given events <span class='clFormula'>$A_1$</span>
, <span class='clFormula'>$A_2$</span><sub>,</sub> and <span class='clFormula'>$B$</span>
, Bayes' rule states that the conditional odds of <span class='clFormula'>$A_1:A_2$</span>
given <span class='clFormula'>$B$</span>
are equal to the marginal odds <span class='clFormula'>$A_1:A_2$</span>
if multiplied by the Bayes' factor.</li>
<li>Bayes' rule shows how one's judgement on whether <span class='clFormula'>$A_1$</span>
or <span class='clFormula'>$A_2$</span>
is true should be updated based on observing the evidence.</li>
<li>Bayesian inference is a method of inference in which Bayes' rule is used to update the probability estimate for a hypothesis as additional evidence is learned.</li>
</ul>

<h4>Key Term</h4>

<dl>
<dt>Bayes' factor</dt>
<dd>The ratio of the conditional probabilities of the event <equation>$B$</equation> given that <equation>$A_1$</equation> is the case or that <equation>$A_2$</equation> is the case, respectively.</dd>
</dl>

<p>In probability theory and statistics, Bayes' theorem (or Bayes' rule ) is a result that is of importance in the mathematical manipulation of conditional probabilities. It is a result that derives from the more basic axioms of probability. When applied, the probabilities involved in Bayes' theorem may have any of a number of probability interpretations. In one of these interpretations, the theorem is used directly as part of a particular approach to statistical inference. In particular, with the Bayesian interpretation of probability, the theorem expresses how a subjective degree of belief should rationally change to account for evidence. This is known as Bayesian inference, which is fundamental to Bayesian statistics.</p>
<p>Bayes' rule relates the odds of event <span class='clFormula'>$A_1$</span>
to event <span class='clFormula'>$A_2$</span>
, before (prior to) and after (posterior to) conditioning on another event <span class='clFormula'>$B$</span>
. The odds on <span class='clFormula'>$A_1$</span>
to event <span class='clFormula'>$A_2$</span>
is simply the ratio of the probabilities of the two events. The relationship is expressed in terms of the likelihood ratio, or Bayes' factor. By definition, this is the ratio of the conditional probabilities of the event <span class='clFormula'>$B$</span>
given that <span class='clFormula'>$A_1$</span>
is the case or that <span class='clFormula'>$A_2$</span>
is the case, respectively. The rule simply states:</p>
<p>
<em>Posterior odds equals prior odds times Bayes' factor.</em>
</p>
<p>More specifically, given events <span class='clFormula'>$A_1$</span>
, <span class='clFormula'>$A_2$</span>
and <span class='clFormula'>$B$</span>
, Bayes' rule states that the conditional odds of <span class='clFormula'>$A_1:A_2$</span>
given <span class='clFormula'>$B$</span>
are equal to the marginal odds <span class='clFormula'>$A_1:A_2$</span>
multiplied by the Bayes factor or likelihood ratio. This is shown in the following formulas:</p>

<div class='clFormula'>$O(A_1:A_2|B) = \Lambda(A_1:A_2|B)\cdot O(A_1:A_2)$</div>

<p>Where the likelihood ratio <span class='clFormula'>$\Lambda$</span>
 is the ratio of the conditional probabilities of the event <span class='clFormula'>$B$</span>
given that <span class='clFormula'>$A_1$</span>
is the case or that <span class='clFormula'>$A_2$</span>
is the case, respectively:</p>

<div class='clFormula'>$\displaystyle \Lambda(A_1:A_2|B) = \frac{P(B|A_1)}{P(B|A_2)}$</div>

<p>Bayes' rule is widely used in statistics, science and engineering, such as in: model selection, probabilistic expert systems based on Bayes' networks, statistical proof in legal proceedings, email spam filters, etc. Bayes' rule tells us how unconditional and conditional probabilities are related whether we work with a frequentist or a Bayesian interpretation of probability. Under the Bayesian interpretation it is frequently applied in the situation where <span class='clFormula'>$A_1$</span>
and <span class='clFormula'>$A_2$</span>
are competing hypotheses, and <span class='clFormula'>$B$</span>
is some observed evidence. The rule shows how one's judgement on whether <span class='clFormula'>$A_1$</span>
or <span class='clFormula'>$A_2$</span>
is true should be updated on observing the evidence.</p>

<h3>Bayesian Inference</h3>

<p>Bayesian inference is a method of inference in which Bayes' rule is used to update the probability estimate for a hypothesis as additional evidence is learned. Bayesian updating is an important technique throughout statistics, and especially in mathematical statistics. Bayesian updating is especially important in the dynamic analysis of a sequence of data. Bayesian inference has found application in a range of fields including science, engineering, philosophy, medicine, and law.</p>

<h3>Informal Definition</h3>

<p>Rationally, Bayes' rule makes a great deal of sense. If the evidence does not match up with a hypothesis, one should reject the hypothesis. But if a hypothesis is extremely unlikely <em>a priori</em>, one should also reject it, even if the evidence does appear to match up.</p>
<p>For example, imagine that we have various hypotheses about the nature of a newborn baby of a friend, including:</p>
<ul>
<li>
<span class='clFormula'>$H_1$</span>
: The baby is a brown-haired boy.</li>
<li>
<span class='clFormula'>$H_2$</span>
: The baby is a blond-haired girl.</li>
<li>
<span class='clFormula'>$H_3$</span>
: The baby is a dog.</li>
</ul>
<p>Then, consider two scenarios:</p>

<ol>
<li>We're presented with evidence in the form of a picture of a blond-haired baby girl. We find this evidence supports <span class='clFormula'>$H_2$</span>
and opposes <span class='clFormula'>$H_1$</span>
and <span class='clFormula'>$H_3$</span>
.</li>
<li>We're presented with evidence in the form of a picture of a baby dog. Although this evidence, treated in isolation, supports <span class='clFormula'>$H_3$</span>
, my prior belief in this hypothesis (that a human can give birth to a dog) is extremely small. Therefore, the posterior probability is nevertheless small.</li>
</ol>
<p>The critical point about Bayesian inference, then, is that it provides a principled way of combining new evidence with prior beliefs, through the application of Bayes' rule. Furthermore, Bayes' rule can be applied iteratively. After observing some evidence, the resulting posterior probability can then be treated as a prior probability, and a new posterior probability computed from new evidence. This allows for Bayesian principles to be applied to various kinds of evidence, whether viewed all at once or over time. This procedure is termed Bayesian updating.</p>



<a href='../images/18072.jpeg'><img class='clImageThumb' src='../images/18072.jpeg' alt='Bayes' Theorem'></a>

<div><b><i>Bayes' Theorem</i></b></div>
<p>A blue neon sign at the Autonomy Corporation in Cambridge, showing the simple statement of Bayes' theorem.</i></p>

<h3 id='concept_175'>8.2.6. The Collins Case</h3>

<blockquote><em>The People of the State of California v. Collins</em> was a 1968 jury trial in California that made notorious forensic use of statistics and probability.</blockquote>

<h4>Learning Objective</h4>

<p>Argue what causes prosecutor's fallacy</p>

<h4>Key Points</h4>

<ul>
<li>Bystanders to a robbery in Los Angeles testified that the perpetrators had been a black male, with a beard and moustache, and a caucasian female with blonde hair tied in a ponytail. They had escaped in a yellow motor car.</li>
<li>A witness of the prosecution, an instructor in mathematics, explained the multiplication rule to the jury, but failed to give weight to independence, or the difference between conditional and unconditional probabilities.</li>
<li>The Collins case is a prime example of a phenomenon known as the prosecutor's fallacy.</li>
</ul>

<h4>Key Terms</h4>

<dl>
<dt>multiplication rule</dt>
<dd>The probability that A and B occur is equal to the probability that A occurs times the probability that B occurs, given that we know A has already occurred.</dd>
<dt>prosecutor's fallacy</dt>
<dd>A fallacy of statistical reasoning when used as an argument in legal proceedings.</dd>
</dl>

<p><em>The People of the State of California v. Collins</em> was a 1968 jury trial in California. It made notorious forensic use of statistics and probability. Bystanders to a robbery in Los Angeles testified that the perpetrators had been a black male, with a beard and moustache, and a caucasian female with blonde hair tied in a ponytail. They had escaped in a yellow motor car.</p>
<p>The prosecutor called upon for testimony an instructor in mathematics from a local state college. The instructor explained the multiplication rule to the jury, but failed to give weight to independence, or the difference between conditional and unconditional probabilities. The prosecutor then suggested that the jury would be safe in estimating the following probabilities:</p>
<ul>
<li>Black man with beard: 1 in 10</li>
<li>Man with moustache: 1 in 4</li>
<li>White woman with pony tail: 1 in 10</li>
<li>White woman with blonde hair: 1 in 3</li>
<li>Yellow motor car: 1 in 10</li>
<li>Interracial couple in car: 1 in 1000</li>
</ul>
<p>These probabilities, when considered together, result in a 1 in 12,000,000 chance that any other couple with similar characteristics had committed the crime - according to the prosecutor, that is. The jury returned a verdict of guilty.</p>
<p>As seen in , upon appeal, the Supreme Court of California set aside the conviction, criticizing the statistical reasoning and disallowing the way the decision was put to the jury. In their judgment, the justices observed that mathematics:</p>



<a href='../images/18087.png'><img class='clImageThumb' src='../images/18087.png' alt='The Collins Case'></a>

<div><b><i>The Collins Case</i></b></div>
<p><i>The Collins case is a classic example of the prosecutor's fallacy. The guilty verdict was reversed upon appeal to the Supreme Court of California in 1968.</i></p>

<p>
<em>... while assisting the trier of fact in the search of truth, must not cast a spell over him.</em>
</p>

<h3>Prosecutor's Fallacy</h3>

<p>The Collins' case is a prime example of a phenomenon known as the prosecutor's fallacy—a fallacy of statistical reasoning when used as an argument in legal proceedings. At its heart, the fallacy involves assuming that the prior probability of a random match is equal to the probability that the defendant is innocent. For example, if a perpetrator is known to have the same blood type as a defendant (and 10% of the population share that blood type), to argue solely on that basis that the probability of the defendant being guilty is 90% makes the prosecutors's fallacy (in a very simple form).</p>
<p>The basic fallacy results from misunderstanding conditional probability, and neglecting the prior odds of a defendant being guilty before that evidence was introduced. When a prosecutor has collected some evidence (for instance, a DNA match) and has an expert testify that the probability of finding this evidence if the accused were innocent is tiny, the fallacy occurs if it is concluded that the probability of the accused being innocent must be comparably tiny. If the DNA match is used to confirm guilt that is otherwise suspected, then it is indeed strong evidence. However, if the DNA evidence is the sole evidence against the accused, and the accused was picked out of a large database of DNA profiles, then the odds of the match being made at random may be reduced. Therefore, it is less damaging to the defendant. The odds in this scenario do not relate to the odds of being guilty; they relate to the odds of being picked at random.</p>
<h2 id='section_35'>8.3. More About Chance</h2>

<h3 id='concept_176'>8.3.1. The Paradox of the Chevalier De Méré</h3>

<blockquote>de Méré observed that getting at least one 6 with 4 throws of a die was more probable than getting double 6's with 24 throws of a pair of dice.</blockquote>

<h4>Learning Objective</h4>

<p>Explain Chevalier de Méré's Paradox when rolling a die</p>

<h4>Key Points</h4>

<ul>
<li>Chevalier de Méré originally thought that rolling a 6 in 4 throws of a die was equiprobable to rolling a pair of 6's in 24 throws of a pair of dice.</li>
<li>In practice, he would win the first bet more than half the time, but lose the second bet more than half the time.</li>
<li>de Méré asked his mathematician friend, Pascal, to help him solve the problem.</li>
<li>The probability of rolling a 6 in 4 throws is <span class='clFormula'>$1-(\frac{5}{6})^4$</span>
, which turns out to be just over 50%.</li>
<li>The probability of rolling two 6's in 24 throws of a pair of dice is <span class='clFormula'>$1-(\frac{35}{36})^{24}$</span>
, which turns out to be just under 50%.</li>
</ul>

<h4>Key Terms</h4>

<dl>
<dt>veridical paradox</dt>
<dd>a situation in which a result appears absurd but is demonstrated to be true nevertheless</dd>
<dt>independent event</dt>
<dd>the fact that <equation>$A$</equation> occurs does not affect the probability that <equation>$B$</equation> occurs</dd>
<dt>equiprobable</dt>
<dd>having an equal chance of occurring mathematically</dd>
</dl>

<h3>Chevalier de Méré</h3>

<p>Antoine Gombaud, Chevalier de Méré (1607 – 1684) was a French writer, born in Poitou. Although he was not a nobleman, he adopted the title Chevalier (Knight) for the character in his dialogues who represented his own views (Chevalier de Méré because he was educated at Méré). Later, his friends began calling him by that name.</p>
<p>Méré was an important Salon theorist. Like many 17<sup>th</sup> century liberal thinkers, he distrusted both hereditary power and democracy. He believed that questions are best resolved in open discussions among witty, fashionable, intelligent people.</p>
<p>He is most well known for his contribution to probability. One of the problems he was interested in was called the <em>problem of points</em>. Suppose two players agree to play a certain number of games -- say, a best-of-seven series -- and are interrupted before they can finish. How should the stake be divided among them if, say, one has won three games and the other has won one?</p>
<p>Another one of his problems has come to be called "De Méré's Paradox," and it is explained below.</p>

<h3>De Mere's Paradox</h3>

<p>Which of these two is more probable:</p>

<ol>
<li>Getting at least one six with four throws of a die or</li>
<li>Getting at least one double six with 24 throws of a pair of dice?</li>
</ol>
<p>The self-styled Chevalier de Méré believed the two to be equiprobable, based on the following reasoning:</p>

<ol>
<li>Getting a pair of sixes on a single roll of two dice is the same probability of rolling two sixes on two rolls of one die.</li>
<li>The probability of rolling two sixes on two rolls is <span class='clFormula'>$\frac{1}{6}$</span>
as likely as one six in one roll.</li>
<li>To make up for this, a pair of dice should be rolled six times for every one roll of a single die in order to get the same chance of a pair of sixes.</li>
<li>Therefore, rolling a pair of dice six times as often as rolling one die should equal the probabilities.</li>
<li>So, rolling 2 dice 24 times should result in as many double sixes as getting one six with throwing one die four times.</li>
</ol>
<p>However, when betting on getting two sixes when rolling 24 times, Chevalier de Méré lost consistently. He posed this problem to his friend, mathematician Blaise Pascal, who solved it.</p>

<h3>Explanation</h3>

<p>Throwing a die is an experiment with a finite number of equiprobable outcomes. There are 6 sides to a die, so there is <span class='clFormula'>$\frac{1}{6}$</span>
probability for a 6 to turn up in 1 throw. That is, there is a <span class='clFormula'>$(\frac{1}{6}) - (\frac{1}{6}) = \frac{5}{6}$</span>
probability for a 6 not to turn up. When you throw a die 4 times, the probability of a 6 not turning up at all is <span class='clFormula'>$(1-\frac{1}{6})^4 = (\frac{5}{6})^4$</span>
. So, there is a probability of <span class='clFormula'>$(\frac{6}{6}) - (\frac{5}{6})^4$</span>
of getting at least one 6 with 4 rolls of a die. If you do the arithmetic, this gives you a probability of approximately 0.5177, or a favorable probability of a 6 appearing in 4 rolls.</p>
<p>Now, when you throw a pair of dice, from the definition of independent events, there is a <span class='clFormula'>$(\frac{1}{6})^2 = \frac{1}{36}$</span>
probability of a pair of 6's appearing. That is the same as saying the probability for a pair of 6's not showing is <span class='clFormula'>$\frac{35}{36}$</span>
. Therefore, there is a probability of <span class='clFormula'>$(\frac{36}{36}) - (\frac{35}{36})^{24}$</span>
of getting at least one pair of 6's with 24 rolls of a pair of dice. If you do the arithmetic, this gives you a probability of approximately 0.4914, or a favorable probability of a pair of 6's <em>not</em> appearing in 24 rolls.</p>
<p>This is a veridical paradox. Counter-intuitively, the odds are distributed differently from how they would be expected to be.</p>



<a href='../images/18098.jpeg'><img class='clImageThumb' src='../images/18098.jpeg' alt='de Méré's Paradox'></a>

<div><b><i>de Méré's Paradox</i></b></div>
<p><i>de Méréobserved that getting at least one 6 with 4 throws of a die was more probable than getting double 6's with 24 throws of a pair of dice.</i></p>

<h3 id='concept_177'>8.3.2. Are Real Dice Fair?</h3>

<blockquote>A fair die has an equal probability of landing face-up on each number.</blockquote>

<h4>Learning Objective</h4>

<p>Infer how dice act as a random number generator</p>

<h4>Key Points</h4>

<ul>
<li>Regardless of what it is made out of, the angle at which the sides connect, and the spin and speed of the roll, a fair die gives each number an equal probability of landing face-up. Every side must be equal, and every set of sides must be equal.</li>
<li>The result of a die roll is determined by the way it is thrown; they are made random by uncertainty due to factors like movements in the thrower's hand. Thus, they are a type of hardware random number generator.</li>
<li>Precision casino dice have their pips drilled, then filled flush with a paint of the same density as the material used for the dice, such that the center of gravity of the dice is as close to the geometric center as possible.</li>
<li>A loaded, weighted, or crooked die is one that has been tampered with to land with a specific side facing upwards more often than it normally would.</li>
</ul>

<h4>Key Terms</h4>

<dl>
<dt>random number</dt>
<dd>number allotted randomly using suitable generator (electronic machine or as simple "generator" as die)</dd>
<dt>pip</dt>
<dd>one of the spots or symbols on a playing card, domino, die, etc.</dd>
<dt>Platonic solid</dt>
<dd>any one of the following five polyhedra: the regular tetrahedron, the cube, the regular octahedron, the regular dodecahedron and the regular icosahedron</dd>
</dl>

<p>A die (plural dice) is a small throw-able object with multiple resting positions, used for generating random numbers. This makes dice suitable as gambling devices for games like craps, or for use in non-gambling tabletop games.</p>
<p>An example of a traditional die is a rounded cube, with each of its six faces showing a different number of dots (pips) from one to six. When thrown or rolled, the die comes to rest showing on its upper surface a random integer from one to six, each value being equally likely. A variety of similar devices are also described as dice; such specialized dice may have polyhedral or irregular shapes and may have faces marked with symbols instead of numbers. They may be used to produce results other than one through six. Loaded and crooked dice are designed to favor some results over others for purposes of cheating or amusement.</p>

<h3>What Makes Dice Fair?</h3>

<p>A fair die is a shape that is labelled so that each side has an equal probability of facing upwards when rolled onto a flat surface, regardless of what it is made out of, the angle at which the sides connect, and the spin and speed of the roll. Every side must be equal, and every set of sides must be equal.</p>
<p>The result of a die roll is determined by the way it is thrown, according to the laws of classical mechanics; they are made random by uncertainty due to factors like movements in the thrower's hand. Thus, they are a type of hardware random number generator. Perhaps to mitigate concerns that the pips on the faces of certain styles of dice cause a small bias, casinos use precision dice with flush markings.</p>
<p>Precision casino dice may have a polished or sand finish, making them transparent or translucent, respectively. Casino dice have their pips drilled, then filled flush with a paint of the same density as the material used for the dice, such that the center of gravity of the dice is as close to the geometric center as possible. All such dice are stamped with a serial number to prevent potential cheaters from substituting a die.</p>
<p>The most common fair die used is the cube, but there are many other types of fair dice. The other four Platonic solids are the most common non-cubical dice; these can make for 4, 8, 12, and 20 faces . The only other common non-cubical die is the 10-sided die.</p>



<a href='../images/18090.jpeg'><img class='clImageThumb' src='../images/18090.jpeg' alt='Platonic Solids as Dice'></a>

<div><b><i>Platonic Solids as Dice</i></b></div>
<p><i>A Platonic solids set of five dice; tetrahedron (four faces), cube/hexahedron (six faces), octahedron (eight faces), dodecahedron (twelve faces), and icosahedron (twenty faces).</i></p>

<h3>Loaded Dice</h3>

<p>A loaded, weighted, or crooked die is one that has been tampered with to land with a specific side facing upwards more often than it normally would. There are several methods for creating loaded dice; these include round and off-square faces and (if not transparent) weights. Tappers have a mercury drop in a reservoir at the center, with a capillary tube leading to another reservoir at a side; the load is activated by tapping the die so that the mercury travels to the side.</p>

</div>
</div>
</body>
</html>
